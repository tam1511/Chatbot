{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4cbgwZWWfWpp"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w93HY88uLXOU",
        "outputId": "b13431f7-3bb3-44db-9bb2-c80e7d7be774"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tAb77yZ9fzMG"
      },
      "source": [
        "# Import modules from llama_index and langchain\n",
        "#!pip install llama_index\n",
        "from llama_index import SimpleDirectoryReader, GPTVectorStoreIndex, LLMPredictor, PromptHelper\n",
        "from langchain import OpenAI\n",
        "import os\n",
        "from IPython.display import Markdown, display"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index import SimpleDirectoryReader,InMemoryStorageContext, GPTVectorStoreIndex, LLMPredictor, PromptHelper\n",
        "from langchain import OpenAI\n",
        "import os\n",
        "from IPython.display import Markdown, display\n",
        "\n",
        "def construct_index(directory_path):\n",
        "    # set maximum input size\n",
        "    max_input_size = 4096\n",
        "    # set number of output tokens\n",
        "    num_outputs = 256\n",
        "    # set maximum chunk overlap\n",
        "    max_chunk_overlap = 20\n",
        "    # set chunk size limit\n",
        "    chunk_size_limit = 600\n",
        "\n",
        "    # define LLM (ChatGPT gpt-3.5-turbo)\n",
        "    llm_predictor = LLMPredictor(llm=OpenAI(temperature=0, model_name=\"gpt-3.5-turbo\", max_tokens=num_outputs))\n",
        "    prompt_helper = PromptHelper(max_input_size, num_outputs, max_chunk_overlap, chunk_size_limit=chunk_size_limit)\n",
        "\n",
        "    documents = SimpleDirectoryReader(directory_path).load_data()\n",
        "\n",
        "    index = GPTVectorStoreIndex(\n",
        "        documents, llm_predictor=llm_predictor, prompt_helper=prompt_helper\n",
        "    )\n",
        "\n",
        "    index.save_to_disk('index.json')\n",
        "\n",
        "    return index\n",
        "\n",
        "\n",
        "\n",
        "def ask_me_anything(question):\n",
        "\n",
        "    index = GPTVectorStoreIndex.load_from_disk('index.json')\n",
        "    response = index.query(question, response_mode=\"compact\")\n",
        "\n",
        "    display(Markdown(f\"You asked: <b>{question}</b>\"))\n",
        "    display(Markdown(f\"Bot says: <b>{response.response}</b>\"))"
      ],
      "metadata": {
        "id": "qNsLNY__Awm3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pafL7Li0jyXW"
      },
      "source": [
        "def construct_index(directory_path):\n",
        "    # set maximum input size\n",
        "    max_input_size = 4096\n",
        "    # set number of output tokens\n",
        "    num_outputs = 256\n",
        "    # set maximum chunk overlap\n",
        "    max_chunk_overlap = 0.2\n",
        "    # set chunk size limit\n",
        "    chunk_size_limit = 600\n",
        "\n",
        "    # define LLM (ChatGPT gpt-3.5-turbo)\n",
        "    llm_predictor = LLMPredictor(llm=OpenAI(temperature=0, model_name=\"gpt-3.5-turbo\", max_tokens=num_outputs))\n",
        "    prompt_helper = PromptHelper(max_input_size, num_outputs, max_chunk_overlap, chunk_size_limit=chunk_size_limit)\n",
        "\n",
        "    documents = SimpleDirectoryReader(directory_path).load_data()\n",
        "\n",
        "    index = GPTVectorStoreIndex.from_documents(\n",
        "        documents, llm_predictor=llm_predictor, prompt_helper=prompt_helper\n",
        "    )\n",
        "\n",
        "    persist_dir = \"/content/drive/MyDrive/chatbot\"  # Specify the directory path where you want to save the index\n",
        "\n",
        "    index.storage_context.persist(persist_dir=persist_dir)\n",
        "\n",
        "    return index\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"OPENAI_API_KEY\"] =\n"
      ],
      "metadata": {
        "id": "ZnhmcnCxhU-v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Construct our index (ONLY NEED TO RUN ONCE! BE CAREFUL THAT THIS COSTS MONEY)\n",
        "# This will take every file in folder, split it into chunks, and embed it with OpenAI's embeddings API.\n",
        "construct_index('/content/drive/MyDrive/chatbot/textdata')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tW5zVE_gLux5",
        "outputId": "f802c2e3-0c8a-4c96-bb4e-9c884db05749"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<llama_index.indices.vector_store.base.VectorStoreIndex at 0x7fe9180d6fe0>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#https://bootcamp.uxdesign.cc/a-step-by-step-guide-to-building-a-chatbot-based-on-your-own-documents-with-gpt-2d550534eea5"
      ],
      "metadata": {
        "id": "MAxz2md8Lyrq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index import StorageContext, load_index_from_storage\n",
        "\n",
        "def ask_me_anything(question):\n",
        "    # Rebuild the storage context\n",
        "    persist_dir = \"/content/drive/MyDrive/chatbot\"  # Specify the directory path where you saved the index files\n",
        "    storage_context = StorageContext.from_defaults(persist_dir=persist_dir)\n",
        "\n",
        "    # Load the index from the index_store.json file\n",
        "    index = load_index_from_storage(storage_context, file_name=\"index_store.json\")\n",
        "\n",
        "    # Query the index for the given question\n",
        "    query_engine = index.as_query_engine()\n",
        "    response = query_engine.query(question)\n",
        "\n",
        "    print(\"You asked:\", question)\n",
        "    print(\"Bot says:\", response.response)\n"
      ],
      "metadata": {
        "id": "bckHdNMFVbq1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"데이터사이언스공부할때 웹크롤링이 필수인가요?\""
      ],
      "metadata": {
        "id": "yq8MWX3Vg8qr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"OPENAI_API_KEY\"] =\n",
        "ask_me_anything(question)"
      ],
      "metadata": {
        "id": "2Xmwr9mthIxM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index import StorageContext, load_index_from_storage\n",
        "import openai\n",
        "\n",
        "def ask_me_anything(question):\n",
        "    # Rebuild the storage context\n",
        "    persist_dir = \"/content/drive/MyDrive/chatbot\"  # Specify the directory path where you saved the index files\n",
        "    storage_context = StorageContext.from_defaults(persist_dir=persist_dir)\n",
        "\n",
        "    # Load the index from the index_store.json file\n",
        "    index = load_index_from_storage(storage_context, file_name=\"index_store.json\")\n",
        "\n",
        "    # Query the index for the given question\n",
        "    query_engine = index.as_query_engine()\n",
        "    response = query_engine.query(question)\n",
        "\n",
        "    print(\"You asked:\", question)\n",
        "    print(\"Bot says:\", response.response)\n",
        "\n",
        "\n",
        "\n",
        "# Set the OpenAI API key\n",
        "openai.api_key =\n",
        "# Call the ask_me_anything function\n",
        "ask_me_anything(question)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e0pwju_yhLGk",
        "outputId": "d4cc0996-6065-4645-e665-4bbc64de89ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "You asked: 데이터사이언스공부할때 웹크롤링이 필수인가요?\n",
            "Bot says: \n",
            "네, 웹크롤링은 데이터사이언스 공부할 때 필수적인 기술입니다. 데이터를 수집하기 위해 파이썬을 이용하는 웹크롤링이 필요합니다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "question = '데이터사이언스공부 어떻게 시작해야해요?'\n",
        "ask_me_anything(question)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YuiQw1pdlQ5R",
        "outputId": "b2a76412-2703-44de-9af6-d0ccc386a6e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "You asked: 데이터사이언스공부 어떻게 시작해야해요?\n",
            "Bot says: \n",
            "데이터사이언스 공부를 시작하기 위해서는 프로그래밍 언어부터 시작하는 것을 추천합니다. 파이썬이나 데이터 수집과 관련된 서버/네트워크/하둡/R 프로그래밍 등을 배우는 것이 좋습니다. 또한 대학교 진학을 데이터사이언스 학과로 진학한 뒤 본격적으로 공부하는 것도 좋은 방법입니다. 그러나 지금 질문자님의 상황에 따라 프로그래밍 언어 위주로 배우는 것을 추천합니다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"정확히 데이터사이언스가 무엇인가요?\""
      ],
      "metadata": {
        "id": "SyWxQVLFjEO-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Call the ask_me_anything function\n",
        "ask_me_anything(question)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ruGEjIQcjGHB",
        "outputId": "99e2b3f2-15d7-47d8-8b28-ef6abb8c1ab4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "You asked: 정확히 데이터사이언스가 무엇인가요?\n",
            "Bot says: \n",
            "데이터 사이언스는 데이터를 연구하는 학문입니다. 심층 분석을 통해 데이터에서 패턴을 찾는 것입니다. 데이터 사이언스의 과정은 데이터에 대한 통찰력을 얻기 위한 추출, 데이터 변환, 데이터 분석 및 예측을 포함합니다. 데이터 사이언스는 기업의 성장 및 제품 품질 향상에 도움이 되는 의사결정 프로세스를 지원하기 위해 사용됩니다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#https://gpt-index.readthedocs.io/en/latest/guides/primer/usage_pattern.html#optional-save-the-index-for-future-use\n"
      ],
      "metadata": {
        "id": "F0aTzyLVi3GE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}